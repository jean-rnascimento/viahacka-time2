{"cells": [{"metadata": {}, "cell_type": "code", "source": "from pyspark.sql.functions import col, to_timestamp, year, month, count, row_number, concat, lit, countDistinct, sum, when, date_sub, ceil\nfrom pyspark.sql import SparkSession\nfrom datetime import datetime, date, timedelta\nfrom dateutil.relativedelta import relativedelta\nimport ibmos2spark, os\nimport pyspark", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "Waiting for a Spark session to start...\nSpark Initialization Done! ApplicationId = app-20210530204327-0000\nKERNEL_ID = 5158353c-6df8-49e6-ae6d-46e5bf9e6246\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "spark = SparkSession.builder.getOrCreate()", "execution_count": 2, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#conexao db2\nDB2_Conexao_grupo02_cert_file_path = os.path.join(os.path.expanduser('~'),'DB2_Conexao_grupo02_ssl.cert')\nf = open(DB2_Conexao_grupo02_cert_file_path, \"w\")\nf.write(\"\"\"LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURFakNDQWZxZ0F3SUJBZ0lKQVA1S0R3ZTNCTkxiTUEwR0NTcUdTSWIzRFFFQkN3VUFNQjR4SERBYUJnTlYKQkFNTUUwbENUU0JEYkc5MVpDQkVZWFJoWW1GelpYTXdIaGNOTWpBd01qSTVNRFF5TVRBeVdoY05NekF3TWpJMgpNRFF5TVRBeVdqQWVNUnd3R2dZRFZRUUREQk5KUWswZ1EyeHZkV1FnUkdGMFlXSmhjMlZ6TUlJQklqQU5CZ2txCmhraUc5dzBCQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBdXUvbitpWW9xdkdGNU8xSGpEalpsK25iYjE4UkR4ZGwKTzRUL3FoUGMxMTREY1FUK0plRXdhdG13aGljTGxaQnF2QWFMb1hrbmhqSVFOMG01L0x5YzdBY291VXNmSGR0QwpDVGcrSUsxbjBrdDMrTHM3d1dTakxqVE96N3M3MlZUSU5yYmx3cnRIRUlvM1JWTkV6SkNHYW5LSXdZMWZVSUtrCldNMlR0SDl5cnFsSGN0Z2pIUlFmRkVTRmlYaHJiODhSQmd0amIva0xtVGpCaTFBeEVadWNobWZ2QVRmNENOY3EKY21QcHNqdDBPTnI0YnhJMVRyUWxEemNiN1hMSFBrWW91SUprdnVzMUZvaTEySmRNM1MrK3labFZPMUZmZkU3bwpKMjhUdGJoZ3JGOGtIU0NMSkJvTTFSZ3FPZG9OVm5QOC9EOWZhamNNN0lWd2V4a0lSOTNKR1FJREFRQUJvMU13ClVUQWRCZ05WSFE0RUZnUVVlQ3JZanFJQzc1VUpxVmZEMDh1ZWdqeDZiUmN3SHdZRFZSMGpCQmd3Rm9BVWVDclkKanFJQzc1VUpxVmZEMDh1ZWdqeDZiUmN3RHdZRFZSMFRBUUgvQkFVd0F3RUIvekFOQmdrcWhraUc5dzBCQVFzRgpBQU9DQVFFQUkyRTBUOUt3MlN3RjJ2MXBqaHV4M0lkWWV2SGFVSkRMb0tPd0hSRnFSOHgxZ2dRcGVEcFBnMk5SCkx3R08yek85SWZUMmhLaWd1d2orWnJ5SGxxcHlxQ0pLOHJEU28xZUVPekIyWmE2S1YrQTVscEttMWdjV3VHYzMKK1UrVTFzTDdlUjd3ZFFuVjU0TVU4aERvNi9sVHRMRVB2Mnc3VlNPSlFDK013ejgrTFJMdjVHSW5BNlJySWNhKwozM0wxNnB4ZEttd1pLYThWcnBnMXJ3QzRnY3dlYUhYMUNEWE42K0JIbzhvWG5YWkh6UG91cldYS1BoaGdXZ2J5CkNDcUdIK0NWNnQ1eFg3b05NS3VNSUNqRVZndnNLWnRqeTQ5VW5iNVZZbHQ0b1J3dTFlbGdzRDNjekltbjlLREQKNHB1REFvYTZyMktZZE4xVkxuN3F3VG1TbDlTU05RPT0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=\"\"\")\nf.close()\n\nDB2_Conexao_grupo02_url = 'jdbc:db2://{}:{}/{}:sslConnection=true;sslTrustStorePassaword={cert};'.format(\n    '44d15047-5d7e-4642-875b-ca7710cd82f5.c1ogj3sd0tgtu0lqde00.databases.appdomain.cloud',\n    30859,\n    'bludb',\n    cert=DB2_Conexao_grupo02_cert_file_path\n)\n\nDATABASE_PROPERTIES={\"user\": \"6a805865\", \"password\": \"\"\"do2Xq3Rhr4rbpjTA\"\"\"}", "execution_count": 3, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Mes atual ano passado\ndtInicio1 = str((date.today() + relativedelta(months= -1, years= -1)).replace(day=1))\ndtFim1 = ((date.today() + relativedelta(months= -1, years= -1)).replace(day=1) + timedelta(days=32)).replace(day=1) - timedelta(days=1)\n\n#Mes Passado ano passado\ndtInicio2 = str((date.today() + relativedelta(months= -2, years= -1)).replace(day=1))\ndtFim2 = ((date.today() + relativedelta(months= -2, years= -1)).replace(day=1) + timedelta(days=32)).replace(day=1) - timedelta(days=1)\n\n#2 Mes Passado\ndtInicio3 = str((date.today() + relativedelta(months= -2)).replace(day=1))\ndtFim3 = ((date.today() + relativedelta(months= -2)).replace(day=1) + timedelta(days=32)).replace(day=1) - timedelta(days=1)\n\n#2 Mes atual\ndtInicio_atu = str((date.today() + relativedelta(months= -1)).replace(day=1))\ndtFim_atu = str(((date.today() + relativedelta(months= -1)).replace(day=1) + timedelta(days=32)).replace(day=1) - timedelta(days=1))\n\nqtdDias1 = (dtFim1.day)\nqtdDias2 = (dtFim2.day)\nqtdDias3 = (dtFim3.day)\n\ndtFim1 = str(dtFim1)\ndtFim2 = str(dtFim2)\ndtFim3 = str(dtFim3)", "execution_count": 4, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#bases necessarias do db2\ncompra = spark.read.format('jdbc') \\\n                   .option('url', DB2_Conexao_grupo02_url) \\\n                   .option('dbtable', '\"HACKATHON\".\"COMPRA\"') \\\n                   .option('user', '6a805865') \\\n                   .option('password', \"\"\"do2Xq3Rhr4rbpjTA\"\"\").load()\n\ncompraentrega = spark.read.format('jdbc') \\\n                     .option('url', DB2_Conexao_grupo02_url) \\\n                     .option('dbtable', '\"HACKATHON\".\"COMPRAENTREGA\"') \\\n                     .option('user', '6a805865') \\\n                     .option('password', \"\"\"do2Xq3Rhr4rbpjTA\"\"\").load()\n\ncompraentregasku = spark.read.format('jdbc') \\\n                     .option('url', DB2_Conexao_grupo02_url) \\\n                     .option('dbtable', '\"HACKATHON\".\"COMPRAENTREGASKU\"') \\\n                     .option('user', '6a805865') \\\n                     .option('password', \"\"\"do2Xq3Rhr4rbpjTA\"\"\").load()\n\nlojista = spark.read.format('jdbc') \\\n                    .option('url', DB2_Conexao_grupo02_url) \\\n                    .option('dbtable', '\"HACKATHON\".\"LOJISTA\"') \\\n                    .option('user', '6a805865') \\\n                    .option('password', \"\"\"do2Xq3Rhr4rbpjTA\"\"\").load()\n\nlojistanps = spark.read.format('jdbc') \\\n                    .option('url', DB2_Conexao_grupo02_url) \\\n                    .option('dbtable', '\"HACKATHON\".\"VISAOLOJISTAVENDANPS\"') \\\n                    .option('user', '6a805865') \\\n                    .option('password', \"\"\"do2Xq3Rhr4rbpjTA\"\"\").load()", "execution_count": 5, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#selecao dos campos necessarios\ndf_compra = compra.select('idcompra',\n                          (to_timestamp('data').alias('datavenda')).cast('date'),\n                          'valortotalcomdesconto',\n                          'flagaprovado',\n                          'idbandeira')\n\ndf_compraentrega = compraentrega.select(col('idcompra').cast('int'),\n                                        col('idlojista').cast('int'),\n                                        col('dataprevisao').cast('date'),\n                                        col('dataentrega').cast('date'),\n                                        col('idbandeira').cast('int'),\n                                        col('idcompraentrega').cast('int'))\n\ndf_compraentregasku = compraentregasku.select(col('idsku').cast('int'),\n                                              col('idcompraentrega').cast('int'),\n                                              col('idbandeira').cast('int'))\n\ndf_lojista = lojista.select(col('idlojista').cast('int'),\n                            col('idbandeira').cast('int'))\n\ndf_lojistanps = lojistanps.select(col('idlojista').cast('int'),\n                                  (to_timestamp('dtaprovacaopedidosite').alias('dataapv')).cast('date'),\n                                  col('qtresposta').cast('int'),\n                                  col('qtrespostadetratora').cast('int'),\n                                  col('qtrespostapromotora').cast('int'))", "execution_count": 6, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#join para capturar os lojistas\ncondicao1 = ['idcompra', 'idbandeira']\ncondicao2 = ['idlojista', 'idbandeira']\ncondicao3 = ['idcompraentrega', 'idbandeira']\n\ndf_join_venda = df_compra.join(df_compraentrega, condicao1, 'inner') \\\n                         .join(df_lojista, condicao2, 'inner') \\\n                         .join(df_compraentregasku, condicao3, 'inner')\n\n#join para capturar as datas de previsao e realizacao da entrega\ncondicao = ['idcompra', 'idbandeira']\n\ndf_join_entrega = df_compra.join(df_compraentrega, condicao, 'inner')", "execution_count": 7, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#cria datasets com os periodos necessarios para os calculos\ndf_d1 = df_join_venda.where(\"datavenda between '\" + dtInicio1 + \"' and '\" + dtFim1 + \"' and flagaprovado = 1\") \\\n                     .groupBy('idlojista') \\\n                     .agg((sum(col('valortotalcomdesconto')) / qtdDias1).alias('VALOR_A_PAS'),\n                          (count(col('idsku')) / qtdDias1).alias('QTD_VENDAS_A_PAS'))\n\ndf_d2 = df_join_venda.where(\"datavenda between '\" + dtInicio2 + \"' and '\" + dtFim2 + \"' and flagaprovado = 1\") \\\n                     .groupBy('idlojista') \\\n                     .agg((sum(col('valortotalcomdesconto')) / qtdDias2).alias('VALOR_AM_PAS'),\n                          (count(col('idsku')) / qtdDias2).alias('QTD_VENDAS_AM_PAS'))\n\ndf_d3 = df_join_venda.where(\"datavenda between '\" + dtInicio3 + \"' and '\" + dtFim3 + \"' and flagaprovado = 1\") \\\n                     .groupBy('idlojista') \\\n                     .agg((sum(col('valortotalcomdesconto')) / qtdDias3).alias('VALOR_M_PAS'),\n                          (count(col('idsku')) / qtdDias3).alias('QTD_VENDAS_M_PAS'),\n                          countDistinct(col('idsku')).alias('QTD_VENDAS_DST_M_PAS'))\n\ndf_atu = df_join_venda.where(\"datavenda between '\" + dtInicio_atu + \"' and '\" + dtFim_atu + \"' and flagaprovado = 1\") \\\n                     .groupBy('idlojista') \\\n                     .agg((sum(col('valortotalcomdesconto')) / qtdDias3).alias('VALOR_M_ATU'),\n                          (count(col('idsku')) / qtdDias3).alias('QTD_VENDAS_M_ATU'),\n                          countDistinct(col('idsku')).alias('QTD_VENDAS_DST_M_ATU'))", "execution_count": 8, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#join entre os datasets\ncondicao = ['idlojista']\n\ndf_join_loj = df_d1.join(df_d2, condicao, 'inner') \\\n                   .join(df_d3, condicao, 'inner') \\\n                   .join(df_atu, condicao, 'inner') \\\n                   .select('idlojista',\n                           'VALOR_A_PAS',\n                           'QTD_VENDAS_A_PAS',\n                           'VALOR_AM_PAS',\n                           'QTD_VENDAS_AM_PAS',\n                           'VALOR_M_PAS',\n                           'QTD_VENDAS_M_PAS',\n                           'QTD_VENDAS_DST_M_PAS',\n                           'VALOR_M_ATU',\n                           'QTD_VENDAS_M_ATU',\n                           'QTD_VENDAS_DST_M_ATU')", "execution_count": 9, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#calculo para gerar as medias\ndf_new_column = df_join_loj.select(col('idlojista'),\n                                   col('VALOR_M_ATU'),\n                                   col('QTD_VENDAS_M_ATU'),\n                                   col('QTD_VENDAS_DST_M_ATU'),\n                                   when((col('VALOR_M_PAS') == 0), 0)\n                                   .when(((col('VALOR_AM_PAS') == 0) | (col('VALOR_A_PAS') == 0)), col('VALOR_M_PAS'))\n                                   .otherwise((col('VALOR_M_PAS') + col('VALOR_A_PAS') + col('VALOR_AM_PAS')) / 3).alias('MEDIA'),\n                                   when((col('QTD_VENDAS_M_PAS') == 0), 0)\n                                   .when(((col('QTD_VENDAS_AM_PAS') == 0) | (col('QTD_VENDAS_A_PAS') == 0)), col('QTD_VENDAS_M_PAS'))\n                                   .otherwise((col('QTD_VENDAS_M_PAS') + col('QTD_VENDAS_A_PAS') + col('QTD_VENDAS_AM_PAS')) / 3).alias('MEDIA_QTD'),\n                                   when((col('QTD_VENDAS_DST_M_PAS') == 0), 0)\n                                   .otherwise(col('QTD_VENDAS_DST_M_PAS')).alias('PROD_QTD_DST'))", "execution_count": 10, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#cria faixas de metas para serem atingidas\ndf_calc_meta = df_new_column.select(col('idlojista').alias('IDLOJISTA'),\n                                    'VALOR_M_ATU',\n                                    'QTD_VENDAS_M_ATU',\n                                    'QTD_VENDAS_DST_M_ATU',\n                                    col('MEDIA').alias('META_VL'),\n                                    (col('MEDIA') + (col('MEDIA') * 0.02)).alias('META_VL_1'),\n                                    (col('MEDIA') + (col('MEDIA') * 0.05)).alias('META_VL_2'),\n                                    (col('MEDIA') + (col('MEDIA') * 0.10)).alias('META_VL_3'),\n                                    (col('MEDIA') + (col('MEDIA') * 0.20)).alias('META_VL_4'),\n                                    'MEDIA_QTD',\n                                    (col('MEDIA_QTD') + (col('MEDIA_QTD') * 0.02)).alias('META_QTD_1'),\n                                    (col('MEDIA_QTD') + (col('MEDIA_QTD') * 0.05)).alias('META_QTD_2'),\n                                    (col('MEDIA_QTD') + (col('MEDIA_QTD') * 0.10)).alias('META_QTD_3'),\n                                    (col('MEDIA_QTD') + (col('MEDIA_QTD') * 0.20)).alias('META_QTD_4'),\n                                    'PROD_QTD_DST',\n                                    when((col('PROD_QTD_DST') < 10), col('PROD_QTD_DST')+1)\n                                    .otherwise(ceil(col('PROD_QTD_DST') + (col('PROD_QTD_DST') * 0.10))).alias('META_QTD_DST_1'),\n                                    when((col('PROD_QTD_DST') < 10), col('PROD_QTD_DST')+2)\n                                    .otherwise(ceil(col('PROD_QTD_DST') + (col('PROD_QTD_DST') * 0.20))).alias('META_QTD_DST_2'),\n                                    when((col('PROD_QTD_DST') < 10), col('PROD_QTD_DST')+3)\n                                    .otherwise(ceil(col('PROD_QTD_DST') + (col('PROD_QTD_DST') * 0.30))).alias('META_QTD_DST_3'),\n                                    when((col('PROD_QTD_DST') < 10), col('PROD_QTD_DST')+4)\n                                    .otherwise(ceil(col('PROD_QTD_DST') + (col('PROD_QTD_DST') * 0.40))).alias('META_QTD_DST_4'))", "execution_count": 11, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#cria score conforme o antigimento das metas\ndf_calc_score_vnd = df_calc_meta.select(col('idlojista').alias('IDLOJISTA'),\n                                        when((col('VALOR_M_ATU') >= col('META_VL')) & (col('VALOR_M_ATU') < col('META_VL_1')), 25)\n                                        .when((col('VALOR_M_ATU') >= col('META_VL_1')) & (col('VALOR_M_ATU') < col('META_VL_2')), 50)\n                                        .when((col('VALOR_M_ATU') >= col('META_VL_2')) & (col('VALOR_M_ATU') < col('META_VL_3')), 100)\n                                        .when((col('VALOR_M_ATU') >= col('META_VL_3')) & (col('VALOR_M_ATU') < col('META_VL_4')), 150)\n                                        .when((col('VALOR_M_ATU') >= col('META_VL_4')), 200)\n                                        .otherwise(lit(0)).alias('SCORE_VALOR'),\n                                        when((col('QTD_VENDAS_M_ATU') >= col('MEDIA_QTD')) & (col('QTD_VENDAS_M_ATU') < col('META_QTD_1')), 25)\n                                        .when((col('QTD_VENDAS_M_ATU') >= col('META_QTD_1')) & (col('QTD_VENDAS_M_ATU') < col('META_QTD_2')), 50)\n                                        .when((col('QTD_VENDAS_M_ATU') >= col('META_QTD_2')) & (col('QTD_VENDAS_M_ATU') < col('META_QTD_3')), 100)\n                                        .when((col('QTD_VENDAS_M_ATU') >= col('META_QTD_3')) & (col('QTD_VENDAS_M_ATU') < col('META_QTD_4')), 150)\n                                        .when((col('QTD_VENDAS_M_ATU') >= col('META_QTD_4')), 200)\n                                        .otherwise(lit(0)).alias('SCORE_QUANTIDADE'),\n                                        when((col('QTD_VENDAS_DST_M_ATU') >= col('PROD_QTD_DST')) & (col('QTD_VENDAS_DST_M_ATU') < col('META_QTD_DST_1')), 25)\n                                        .when((col('QTD_VENDAS_DST_M_ATU') >= col('META_QTD_DST_1')) & (col('QTD_VENDAS_DST_M_ATU') < col('META_QTD_DST_2')), 50)\n                                        .when((col('QTD_VENDAS_DST_M_ATU') >= col('META_QTD_DST_2')) & (col('QTD_VENDAS_DST_M_ATU') < col('META_QTD_DST_3')), 100)\n                                        .when((col('QTD_VENDAS_DST_M_ATU') >= col('META_QTD_DST_3')) & (col('QTD_VENDAS_DST_M_ATU') < col('META_QTD_DST_4')), 150)\n                                        .when((col('QTD_VENDAS_DST_M_ATU') >= col('META_QTD_DST_4')), 200)\n                                        .otherwise(lit(0)).alias('SCORE_MIX_PRODUTOS'))", "execution_count": 12, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#FILTROS NECESSARIOS\ndf_join_entrega = df_join_entrega.where(\"datavenda between '\" + dtInicio_atu + \"' and '\" + dtFim_atu + \"' and flagaprovado = 1 and dataentrega is not null\")\ndf_lojistanps = df_lojistanps.where(\"dataapv between '\" + dtInicio_atu + \"' and '\" + dtFim_atu + \"'\")", "execution_count": 13, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#MAPEANDO AS ENTREGAS DE ACORDO COM O INTERVALO ENTRE DATA DE PRECISAO E DATA DE ENTREGA\ndf_new_col = df_join_entrega.withColumn('ENTREGA_ANTES', when(col('dataprevisao') > col('dataentrega'), lit(1)).otherwise(lit(0))) \\\n                            .withColumn('ENTREGA_NA_DATA', when(col('dataprevisao') == col('dataentrega'), lit(1)).otherwise(lit(0))) \\\n                            .withColumn('ENTREGA_ATRASO_P', when(col('dataprevisao') == date_sub(col('dataentrega'), 1), lit(1)).otherwise(lit(0))) \\\n                            .withColumn('ENTREGA_ATRASO_G', when(col('dataprevisao') <= date_sub(col('dataentrega'), 2), lit(1)).otherwise(lit(0)))", "execution_count": 14, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#SOMANDO O MAPEAMENTO POR LOJISTA\ndf_columns = df_new_col.groupBy('idlojista').agg(sum(col('ENTREGA_ANTES')).alias('ENTREGA_ANTES'), \\\n                                                 sum(col('ENTREGA_NA_DATA')).alias('ENTREGA_NA_DATA'), \\\n                                                 sum(col('ENTREGA_ATRASO_P')).alias('ENTREGA_ATRASO_P'), \\\n                                                 sum(col('ENTREGA_ATRASO_G')).alias('ENTREGA_ATRASO_G'), \\\n                                                 sum(col('ENTREGA_ANTES') + col('ENTREGA_NA_DATA') + col('ENTREGA_ATRASO_P') + col('ENTREGA_ATRASO_G')).alias('TOTAL'))\n\n#SOMANDO O NPS POR LOJISTA\ndf_nps = df_lojistanps.groupBy('idlojista').agg(sum(col('qtresposta')).alias('qtresposta'),\n                                                sum(col('qtrespostadetratora')).alias('qtrespostadetratora'),\n                                                sum(col('qtrespostapromotora')).alias('qtrespostapromotora'))", "execution_count": 15, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#CALCULO DO SCORE\ndf_score_ent = df_columns.select('IDLOJISTA',\n                             ceil(((((col('ENTREGA_NA_DATA') + col('ENTREGA_ANTES') * 2) - (col('ENTREGA_ATRASO_P') + col('ENTREGA_ATRASO_G') * 2)) * 100) / col('TOTAL'))).alias('SCORE_ENTREGA'))\n\n#CALCULO DO NPS\ndf_score_nps = df_nps.select('IDLOJISTA',\n                            ceil(((col('qtrespostapromotora')-col('qtrespostadetratora'))*100)/col('qtresposta')).alias('SCORE_NPS'))", "execution_count": 16, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#JOIN PARA JUNTAR OS SCORE_ENTREGA, SCORE_NPS e SCORE_VENDA\ncondicao = ['IDLOJISTA']\n\ndf_join_score = df_calc_score_vnd.join(df_score_ent, condicao, 'left') \\\n                                 .join(df_score_nps, condicao, 'left')", "execution_count": 17, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#AJUSTANDO OS SCORES NEGATIVOS OU NULOS PARA 0\ndf_final = df_join_score.withColumn('SCORE_ENTREGA', when((col('SCORE_ENTREGA').isNull()) | (col('SCORE_ENTREGA') < 0), lit(0)).otherwise(col('SCORE_ENTREGA'))) \\\n                        .withColumn('SCORE_NPS', when((col('SCORE_NPS').isNull()) | (col('SCORE_NPS') < 0), lit(0)).otherwise(col('SCORE_NPS')))", "execution_count": 18, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#ESCREVENDO O DATAFRAME FINAL NO DB2\ndf_final.write.jdbc(url=DB2_Conexao_grupo02_url,\n                    table='GRUPO2.TB_SCORE_LOJISTA',\n                    mode='overwrite',\n                    properties=DATABASE_PROPERTIES)", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python37", "display_name": "Python 3.7 with Spark", "language": "python3"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "name": "python", "pygments_lexer": "ipython3", "version": "3.7.10", "file_extension": ".py", "codemirror_mode": {"version": 3, "name": "ipython"}}}, "nbformat": 4, "nbformat_minor": 1}